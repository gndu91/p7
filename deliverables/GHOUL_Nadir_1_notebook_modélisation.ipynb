{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from requests import get, Response\n",
    "from hashlib import sha256\n",
    "from tqdm.notebook import tqdm\n",
    "from zipfile import ZipFile\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from lightgbm import LGBMClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Added imports for the new transformer\n",
    "from scipy import stats\n",
    "from random import sample\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from deliverables.utils.image_inverter import save\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, cross_validate, GridSearchCV, \\\n",
    "    ParameterGrid\n",
    "from mlflow import set_tracking_uri, log_metrics, log_figure\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ],
   "id": "cfb6a2fa6e36e0b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Partie 0 - Constantes, imports et outils",
   "id": "e438bb10601c63b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_cache_folder = Path('~/.cache/gn_p7').expanduser()\n",
    "_cache_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_ds_url = 'https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Impl%C3%A9menter+un+mod%C3%A8le+de+scoring/Projet+Mise+en+prod+-+home-credit-default-risk.zip'\n",
    "\n",
    "graph_folder: Path = Path(\"./graphs\")\n",
    "random_state: int = 42\n",
    "\n",
    "\n",
    "def save_figure(figure: plt.Figure, folder: str, figure_name: str) -> None:\n",
    "    folder = graph_folder / folder\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    save(figure, folder / f'{figure_name}.png', close=True)\n",
    "\n",
    "\n",
    "def download(url: str) -> Path:\n",
    "    url_id: str = sha256(url.encode('utf-8')).hexdigest()\n",
    "    local_path: Path = _cache_folder / url_id\n",
    "    local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not local_path.exists():\n",
    "        tmp_path: Path = _cache_folder / (url_id + '.tmp')\n",
    "        res: Response = get(url, stream=True)\n",
    "        with tmp_path.open('wb') as f, tqdm(\n",
    "                total=int(res.headers.get('content-length')),\n",
    "                desc=f'Downloading {url}',\n",
    "                unit_scale=True) as q:\n",
    "            for chunk in res.iter_content(chunk_size=8192):\n",
    "                q.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "        tmp_path.replace(local_path)\n",
    "    return local_path\n",
    "\n",
    "\n",
    "def download_zip_archive(url: str) -> Path:\n",
    "    \"\"\"Download a zip archive, extract it then return the folder containing its content\"\"\"\n",
    "    archive_path: Path = download(url)\n",
    "    archive_folder: Path = Path(archive_path.as_posix() + '.dir')\n",
    "\n",
    "    if not archive_folder.exists():\n",
    "        print(f'Extracting archive {url}...', flush=True)\n",
    "        archive_temp: Path = Path(archive_path.as_posix() + '.tmp')\n",
    "        archive_temp.mkdir(parents=True, exist_ok=True)\n",
    "        archive: ZipFile = ZipFile(archive_path)\n",
    "        archive.extractall(path=archive_temp)\n",
    "        archive_temp.replace(archive_folder)\n",
    "        print(f'Extracting archive {url}...done', flush=True)\n",
    "\n",
    "    return archive_folder\n",
    "\n",
    "\n",
    "datasets: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "\n",
    "def get_dataset(name: str) -> pd.DataFrame:\n",
    "    folder = download_zip_archive(_ds_url)\n",
    "    if not name.endswith('.csv'):\n",
    "        name = f'{name}.csv'\n",
    "    try:\n",
    "        return datasets[name]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            _df = pd.read_csv(folder / name)\n",
    "        except FileNotFoundError:\n",
    "            display(Markdown(f'# ERROR: Dataset {name!r} not found, available datasets are:\\n' + '\\n'.join(\n",
    "                f'- {p.name}' for p in sorted(folder.iterdir(), key=(lambda x: x.name.lower())))))\n",
    "            raise KeyError(name) from None\n",
    "        else:\n",
    "            datasets[name] = _df\n",
    "            return _df.copy()\n"
   ],
   "id": "52eebf7590d1f3bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Partie 1 - EDA\n",
    "\n",
    "## Partie 1.0 - Chargement des données"
   ],
   "id": "da553995ee1ac61f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = map(get_dataset, ('application_train', 'application_test'))\n",
    "train_ratio = len(train) / (len(train) + len(test))\n",
    "test_ratio = len(test) / (len(train) + len(test))\n",
    "train_df, test_df = train, test = train_test_split(\n",
    "    train,\n",
    "    test_size=test_ratio,\n",
    "    random_state=random_state,\n",
    "    stratify=train['TARGET']\n",
    ")"
   ],
   "id": "9230c95ae363f990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Séparation des features et de la cible\n",
    "X = train_df.drop('TARGET', axis=1)\n",
    "y = train_df['TARGET']\n",
    "\n",
    "print(\"Données d'entraînement chargées :\", X.shape)\n",
    "print(\"Cible chargée :\", y.shape)"
   ],
   "id": "103c06f72bb9e2ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Séparation des features et de la cible\n",
    "X = test_df.drop('TARGET', axis=1)\n",
    "y = test_df['TARGET']\n",
    "\n",
    "print(\"Données de test chargées :\", X.shape)\n",
    "print(\"Cible chargée :\", y.shape)"
   ],
   "id": "8e6fb843faf25758",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train",
   "id": "161854566122bfae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test",
   "id": "2099de0fe2561b2a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Partie 1.1 - Analyse de la cible\n",
    "\n",
    "La cible est présente dans le dataset d'entrainement mais pas dans le dataset de test, pour éviter les fuites de données."
   ],
   "id": "1a216db8d58ab4fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_figure(train.TARGET.value_counts().plot.pie(\n",
    "    title='Répartition des cibles (0=paiement complet, 1=retards de paiement)'\n",
    ").figure, '1_model', '0_target')"
   ],
   "id": "5cd5272235804ee7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Partie 1.3 - Analyse des features (hors cible)",
   "id": "550bc328db329346"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Function to calculate missing values by column# Funct\n",
    "def missing_values_table(df):\n",
    "    # Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    "\n",
    "    # Percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "\n",
    "    # Make a table with the results\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "\n",
    "    # Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "\n",
    "    # Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    # Print some summary information\n",
    "    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n",
    "                                                              \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "          \" columns that have missing values.\")\n",
    "\n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "\n",
    "def missing_stats():\n",
    "    for fold in ('train', 'test'):\n",
    "        msno.matrix(get_dataset('application_' + fold + '.csv'), fontsize=12)\n",
    "        plt.title(f'Missing Values Count ({fold.title()}ing fold)', fontsize=16)\n",
    "        save_figure(plt.gcf(), '1_model', '1_missing_' + fold.title())\n",
    "\n",
    "    for fold in ('train', 'test'):\n",
    "        df = get_dataset('application_' + fold + '.csv')\n",
    "        msno.matrix(df[list(sorted(df.columns, key=(lambda col: int(df[col].notna().sum()))))], fontsize=12)\n",
    "        plt.title(f'Missing Values Count ({fold.title()}ing fold)', fontsize=16)\n",
    "        save_figure(plt.gcf(), '1_model', '2_sorted_missing_' + fold.title())\n",
    "\n",
    "    for fold in ('train', 'test'):\n",
    "        missing_test_values = missing_values_table(get_dataset('application_' + fold + '.csv'))\n",
    "\n",
    "        # TODO: Set the plot style for dark mode when exporting to png\n",
    "        plt.figure(figsize=(16, 12))  # There are a lot of columns\n",
    "        sns.barplot(x=missing_test_values['% of Total Values'], y=missing_test_values.index)\n",
    "        plt.title(f'Percentage of Missing Values by Feature ({fold.title()}ing fold)', fontsize=16)\n",
    "        plt.xlabel('% of Total Values', fontsize=12)\n",
    "        plt.ylabel('Features', fontsize=12)\n",
    "\n",
    "        # Add percentage text on the bars\n",
    "        for index, value in enumerate(missing_test_values['% of Total Values']):\n",
    "            plt.text(value, index, f' {value}%', va='center')\n",
    "\n",
    "        plt.xlim(0, 110)  # Set x-limit to give space for text\n",
    "        plt.tight_layout()\n",
    "        save_figure(plt.gcf(), '1_model', '3_graph_missing' + fold.title())\n",
    "\n",
    "\n",
    "missing_stats()"
   ],
   "id": "6a22f787f2127f61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nous pouvons voir qu'à peu près la moitié des colonnes manquent au moins une valeur, et que le reste est défini à environ 45-75%\n",
    "Si nous nous intéressons"
   ],
   "id": "e54113cada4b4976"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "assert not len(train.columns[\n",
    "                   (train.dtypes != 'int64') &\n",
    "                   (train.dtypes != 'float64') &\n",
    "                   (train.dtypes != 'object')]), 'Plus de types de colonnes sont présentes'\n",
    "display(Markdown('Il existe trois types de données en entrée, int64 et float64, numériques, et object, catégorielles'))\n",
    "display(\n",
    "    Markdown('Il arrive parfois que des données numériques soient accidentellement catégorisées en \"object\" si elles'\n",
    "             ' contiennent des valeurs non numérique, ce n\\'est pas le cas ici'))"
   ],
   "id": "dc8d94dc719297ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Partie 2 - Définition du Score Métier\n",
    "\n",
    "Nous somme face à deux déséquilibres:\n",
    "- Un déséquilibre des coûts (pb métier) : un faux négatif coûtant dix fois plus cher qu'un faux positif, il faut en tenir compte pour minimiser plus fortement les faux négatifs.\n",
    "    - Nous devons créer un `scorer` pour Scikit-Learn qui minimise le coût `coût = 10 * FN + 1 * FP`\n",
    "    - Il doit aussi trouver le seuil de décision optimal, car le seuil par défaut de 0.5 n'est probablement pas le meilleur d'un point de vue métier.\n",
    "- Un déséquilibre des classes (pb données) : 92% des cibles étant négatives, un risque serai accru d'avoir un modèle prédisant trops 0 (prédire 0 tout le temps nous donnera 92% de précision.\n",
    "    - Cela sera traité en utilisant comme paramètre `class_weight='balanced'`\n",
    "    - TODO: Don't forget to include it every time I introduce a new model"
   ],
   "id": "92c44add145e5c8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_optimal_threshold(y_true: np.ndarray, y_pred_proba: np.ndarray):\n",
    "    \"\"\"Trouve le seuil qui minimise le coût métier.\"\"\"\n",
    "    # Si y_pred_proba est 2D, on prend la probabilité de la classe 1\n",
    "    if y_pred_proba.ndim == 2:\n",
    "        y_scores = y_pred_proba[:, 1]\n",
    "    # Sinon, on suppose que c'est déjà le score pour la classe positive\n",
    "    else:\n",
    "        y_scores = y_pred_proba\n",
    "\n",
    "    thresholds = np.linspace(0.01, 0.99, 100)\n",
    "    costs = []\n",
    "    for t in thresholds:\n",
    "        y_pred = (y_scores >= t).astype(int)  # On utilise y_scores ici\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "        costs.append(10 * fn + 1 * fp)\n",
    "\n",
    "    optimal_t_index = np.argmin(costs)\n",
    "    return thresholds[optimal_t_index], costs[optimal_t_index]\n",
    "\n",
    "\n",
    "def business_cost_scorer_func(y_true: np.ndarray[..., ...], y_pred_proba: np.ndarray[..., ...]):\n",
    "    \"\"\"Calcule le coût métier minimal en trouvant le meilleur seuil.\"\"\"\n",
    "    _, min_cost = find_optimal_threshold(y_true, y_pred_proba)\n",
    "    return min_cost\n",
    "\n",
    "\n",
    "def optimal_threshold_scorer_func(y_true: np.ndarray[..., ...], y_pred_proba: np.ndarray[..., ...]):\n",
    "    \"\"\"Retourne le seuil optimal qui minimise le coût métier.\"\"\"\n",
    "    optimal_t, _ = find_optimal_threshold(y_true, y_pred_proba)\n",
    "    return optimal_t\n",
    "\n",
    "\n",
    "# Création des scorers pour Scikit-Learn\n",
    "# On veut MINIMISER le coût, donc greater_is_better=False\n",
    "business_scorer = make_scorer(business_cost_scorer_func, greater_is_better=False, response_method='predict_proba')\n",
    "\n",
    "# Pour le seuil, c'est juste une information, donc pas de notion de 'meilleur'\n",
    "threshold_scorer = make_scorer(optimal_threshold_scorer_func, response_method='predict_proba')\n",
    "\n",
    "# On définit le dictionnaire de scoring qu'on utilisera dans la cross-validation\n",
    "scoring = {\n",
    "    'business_cost': business_scorer,\n",
    "    'business_threshold': threshold_scorer,\n",
    "    'roc_auc': 'roc_auc',\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1': 'f1',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall'\n",
    "}\n",
    "print(\"Scorers métier créés avec succès.\")"
   ],
   "id": "5d86bc44377ae63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Partie 3 - Définition d'un pipeline de prétraitement\n",
    "\n",
    "L'avantage que le pipeline de prétraitement a est la robustesse contrer le data leakage, en effet les modèles d'apprentissages et de traitement seront entraîné sur les mêmes données, ce qui sera obligatoire pour pouvoir utiliser des techniques de K Fold en s'assurant que les folds soient indépendants les uns des autres.\n",
    "\n",
    "Note: Nous allons ignorer la transformation BoxCox en premier lieu\n",
    "\n",
    "Note relatives au déséquilibre de la cible:<br>\n",
    "Il existe un déséquilibre flagrant entre 1 et 0, avec 1 n'étant présent que pour 8% des données d'entraînement.<br>\n",
    "Pour y remédier, on a a notre disposition:\n",
    "- oversampling, par exemple SMOT: Synthetic Minority OverSampling Technique\n",
    "- undersampling\n",
    "- cost sensitive learning: Ajuster le scoring pour pénaliser davantage les faux négatifs\n",
    "\n",
    "\n",
    "\n",
    "TODO: Revoir s'il est nécessaire de tester les trois, ou si cost sensitive learning est suffisant\n"
   ],
   "id": "79264bad67f6fe58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import wraps\n",
    "from typing import Callable, Any\n",
    "\n",
    "\n",
    "class OccupationPCA(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    ORGANIZATION_TYPE et OCCUPATION_TYPE donnent 78 colonnes après OneHot, ce qui complexifie le dataset.\n",
    "    En théorie cela nous donne 37 colonnes post pca\n",
    "    Pour minimiser le nombre de features, nous allons procéder de la manière suivante:\n",
    "    1. Application d'un One-Hot Encoding sur les colonnes 'ORGANIZATION_TYPE' et 'OCCUPATION_TYPE'.\n",
    "    2. Application d'une ACP pour conserver 95% de la variance, en nommant composantes 'OT_0', 'OT_1', etc.\n",
    "    5. Suppression des colonnes d'origine et ajout des nouvelles composantes au DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components=0.95):\n",
    "        self.n_components = n_components  # Will either be a variance or number of components\n",
    "        self.pca = PCA(n_components=self.n_components)  # This will be \"fitted\" with the estimator\n",
    "\n",
    "        # To make sure the dataset holds the same shape, even if some values are missing from the testing dataset\n",
    "        self.dummy_columns = []\n",
    "\n",
    "    # TODO: Dummy NA?\n",
    "    def fit(self, X, y=None):\n",
    "        x = pd.get_dummies(X[['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']], dummy_na=True)\n",
    "        self.dummy_columns = x.columns\n",
    "        self.pca.fit(x)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = X.copy()\n",
    "        x_org = pd.get_dummies(x[['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']], dummy_na=True)\n",
    "\n",
    "        # Add, remove and move around columns to get the same shape as the training set\n",
    "        x_org = x_org.reindex(columns=self.dummy_columns, fill_value=0)\n",
    "\n",
    "        pca_result = self.pca.transform(x_org)  # Apply pre-trained PCA\n",
    "\n",
    "        # Turning the results into a dataframe to include to x\n",
    "        pca_df = pd.DataFrame(pca_result, columns=[f\"OT_{i}\" for i in range(pca_result.shape[1])], index=x.index)\n",
    "\n",
    "        # Replacing old values with new pca values\n",
    "        return pd.concat([x.drop(columns=['ORGANIZATION_TYPE', 'OCCUPATION_TYPE']), pca_df], axis=1)\n",
    "\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, handle_unknown='ignore', sparse_output=False):\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.sparse_output = sparse_output\n",
    "        self.ohe = OneHotEncoder(handle_unknown=self.handle_unknown,\n",
    "                                 sparse_output=self.sparse_output)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.categorical_columns_ = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        if self.categorical_columns_:\n",
    "            self.ohe.fit(X[self.categorical_columns_])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        if self.categorical_columns_:\n",
    "            encoded_data = self.ohe.transform(X[self.categorical_columns_])\n",
    "            new_cols = self.ohe.get_feature_names_out(self.categorical_columns_)\n",
    "            encoded_df = pd.DataFrame(encoded_data, columns=new_cols, index=X.index)\n",
    "            X_transformed = X_transformed.drop(columns=self.categorical_columns_)\n",
    "            X_transformed = pd.concat([X_transformed, encoded_df], axis=1)\n",
    "        return X_transformed\n",
    "\n",
    "\n",
    "def copy_and_return_x[T, U](callback: Callable[[T, U], None]) -> Callable[[T, U], T]:\n",
    "    @wraps(callback)\n",
    "    def wrapped(x: T, y: U = None) -> T:\n",
    "        callback((x := x.copy()), y)\n",
    "        return x\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "@FunctionTransformer\n",
    "@copy_and_return_x\n",
    "def custom_preprocessor(X, y=None) -> None:\n",
    "    # On commence par réparer l'erreur que nous avons vu à l'étape d'Analyse Exploratoire\n",
    "    X['DAYS_EMPLOYED'] = X['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "\n",
    "    # On va ensuite supprimer la variable identifiant\n",
    "    X.pop('SK_ID_CURR')  # TODO: Check for this\n",
    "\n",
    "    # On va enfin traiter les valeurs catégorielles\n",
    "\n",
    "    # TODO: Vaut-il mieux utiliser trois colonnes?\n",
    "    X['CODE_GENDER'] = X['CODE_GENDER'].map({'F': 1, 'M': -1}).fillna(0)\n",
    "\n",
    "    for flag_name in X.columns[X.columns.str.startswith('FLAG_')]:\n",
    "        values = set(X[flag_name])\n",
    "        if {0, 1} - values:\n",
    "            continue\n",
    "        if {\"Y\", \"N\"} - values:\n",
    "            X[flag_name] = X[flag_name].map({'Y': 1, 'N': 0})\n",
    "        else:\n",
    "            raise RuntimeError(flag_name, values)\n",
    "\n",
    "\n",
    "@FunctionTransformer\n",
    "@copy_and_return_x\n",
    "def sanitize_feature_names(x, y=None):\n",
    "    x.columns = [re.sub(r'[^A-Za-z0-9_]+', '', str(col)) for col in x.columns.tolist()]\n",
    "\n",
    "\n",
    "# 2. Build the pipeline\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('custom_preprocessor', custom_preprocessor),\n",
    "    ('occupation_pca', OccupationPCA()),\n",
    "    ('first_name_sanitization', deepcopy(sanitize_feature_names)),\n",
    "    ('dummy_preprocessor', CategoricalEncoder(handle_unknown='ignore', sparse_output=False)),\n",
    "    ('second_name_sanitization', deepcopy(sanitize_feature_names)),\n",
    "], verbose=True)\n",
    "\n",
    "# We try to see if the pipeline works as expected\n",
    "X_train = train.copy()\n",
    "y_train = X_train.pop('TARGET')\n",
    "deepcopy(preprocessing_pipeline).fit_transform(X_train, y_train)"
   ],
   "id": "43cf317c3856ab17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Partie 4: Outils",
   "id": "bc939837b9eb8787"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TODO: Danger of this, if values are negatives and test values are smaller than train values, offset won't be enough\n",
    "# I don't want the BoxCox transformer to mess up data that it cannot fix.\n",
    "# TODO: Review how I estimate if it's worth the transformation\n",
    "epsilon = 1e-6\n",
    "\n",
    "\n",
    "class ConditionalBoxCox(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, p_value_threshold: float = 0.05):\n",
    "        self.p_value_threshold = p_value_threshold\n",
    "        self.columns_to_transform_ = []\n",
    "        self.learned = {}\n",
    "\n",
    "    def _as_numpy(self, X: pd.DataFrame | np.ndarray[tuple[int, ...], np.dtype[np.float64]]):\n",
    "        x: np.ndarray\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            for col in X.columns:\n",
    "                if X[col].isna().any():\n",
    "                    raise NotImplementedError(\n",
    "                        'I do not know yet how this would be handled,\\n\\t'\n",
    "                        'for now, you need this to follow an inputer to have no null values')\n",
    "            columns_to_drop = [i for i in X.columns if X[i].dtype == 'object']\n",
    "            columns_to_keep = [i for i in X.columns if X[i].dtype in ('float64', 'int64')]\n",
    "            if len(other_columns := set(X.columns) - set(columns_to_keep) - set(columns_to_drop)):\n",
    "                raise NotImplementedError(other_columns)\n",
    "            x = X.to_numpy()\n",
    "        elif isinstance(X, np.ndarray):\n",
    "            x = X\n",
    "        else:\n",
    "            raise NotImplementedError(type(X))\n",
    "        return x\n",
    "\n",
    "    # noinspection PyTypeHints\n",
    "    def fit(self, X: pd.DataFrame | np.ndarray[tuple[int, ...], np.dtype[np.float64]], y=None):\n",
    "        x = self._as_numpy(X.copy())\n",
    "\n",
    "        for col, data in enumerate(x.T):\n",
    "            if len(set(data)) < 10:  # Not worth the change\n",
    "                continue\n",
    "            data = data + (shift := epsilon - (0 if (data > 0).all() else data.min()))\n",
    "            _, initial_p = stats.shapiro(sample(list(data), 100))\n",
    "            transformed_data, ld = stats.boxcox(data)\n",
    "            _, transformed_p = stats.shapiro(sample(list(transformed_data), 100))\n",
    "            if transformed_p > initial_p and transformed_p > self.p_value_threshold:\n",
    "                self.columns_to_transform_.append(col)\n",
    "                self.learned[col] = ld, shift\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        x = self._as_numpy(X.copy())\n",
    "        for index in self.columns_to_transform_:\n",
    "            ld, shift = self.learned[index]\n",
    "            x[:, index] = stats.boxcox(\n",
    "                x[:, index] + shift, lmbda=ld)\n",
    "        return x\n",
    "\n",
    "\n",
    "def new_pipeline(*steps):\n",
    "    return Pipeline(deepcopy(preprocessing_pipeline.steps) + list(steps))"
   ],
   "id": "379a1e1a0666c4b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Partie 5: Pipelines de modélisation\n",
    "\n",
    "Nous allons maintenant définir nos modèles et lancer les expérimentations. Chaque modèle sera testé dans un `run` MLflow distinct.\n",
    "\n",
    "Pour chaque `run`, nous allons logger :\n",
    "1.  **Les paramètres** : Tous les hyperparamètres du pipeline.\n",
    "2.  **Les métriques** : Les scores (AUC, coût métier, seuil) calculés par validation croisée (moyenne et écart-type).\n",
    "3.  **Le modèle final** : Le pipeline complet, entraîné sur l'ensemble des données, prêt à être déployé.\n",
    "4.  **(Optionnel) Des artefacts** : Comme des graphiques (ex: feature importance)."
   ],
   "id": "525922cf91034380"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from mlflow import set_experiment, start_run, log_params, log_metric, log_param, models, sklearn\n",
    "\n",
    "# TODO: `random_state`\n",
    "\n",
    "# Définition des modèles de prétraitement\n",
    "pipelines = [\n",
    "    ('DummyClassifier', new_pipeline(('model', DummyClassifier(strategy='stratified'))), {}),\n",
    "    ('LogisticRegression', new_pipeline(\n",
    "        ('imputer', SimpleImputer()),\n",
    "        ('coxbox', ConditionalBoxCox()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(class_weight='balanced'))), {\n",
    "         'model__C': [0.1, 1.0, 10.0], 'model__max_iter': [100, 1000]}),\n",
    "    ('LightGBMClassifier', new_pipeline(('model', LGBMClassifier(class_weight='balanced'))), {\n",
    "        'model__n_estimators': [100, 200], 'model__learning_rate': [0.05, 0.1], 'model__num_leaves': [20, 31]})\n",
    "]\n",
    "pipelines = [pipelines[-1]]\n",
    "\n",
    "# Définition de la stratégie de validation croisée\n",
    "cv_strategy = RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=random_state)\n",
    "\n",
    "X_train = train.copy()\n",
    "y_train = X_train.pop('TARGET')\n",
    "deepcopy(preprocessing_pipeline).fit_transform(X_train, y_train)\n",
    "X_train = train.copy()\n",
    "y_train = X_train.pop('TARGET')\n",
    "\n",
    "display(Markdown(f\"***{len(pipelines)}*** modèles sont prêts à être testés.\"))\n",
    "\n",
    "# MLFlow\n",
    "set_tracking_uri('http://127.65.12.247:50222')\n",
    "set_experiment(\"P7_Credit_Scoring_Models\")\n",
    "\n",
    "best_global_score = float('inf')  # On veut minimiser le coût, donc on part de l'infini\n",
    "best_model = None  # Cette variable stockera le meilleur pipeline trouvé\n",
    "best_model_name = \"\"\n",
    "best_params = {}\n",
    "\n",
    "# Boucle d'expérimentation\n",
    "for model_name, pipeline_base, grid_params in pipelines:\n",
    "    print(f\"--- Lancement du run pour le modèle : {model_name} ---\")\n",
    "\n",
    "    grid = list(ParameterGrid(grid_params)) or [{}]  # In case there are no hyper parameters\n",
    "\n",
    "    # Cette boucle manuelle me permet de logger toutes les métrique, et non pas uniquement les bonnes\n",
    "    with start_run(run_name=model_name) as run:\n",
    "\n",
    "        local_best_global_score = float('inf')  # On veut minimiser le coût, donc on part de l'infini\n",
    "        local_best_model = None  # Cette variable stockera le meilleur pipeline trouvé\n",
    "        local_best_model_name = \"\"\n",
    "        local_best_params = {}\n",
    "\n",
    "        for parameters_index, parameters_data in enumerate(grid):\n",
    "            run_name: str = f'{model_name}_run_{parameters_index + 1}'\n",
    "\n",
    "            print(f\"  > Run: {run_name} avec les paramètres : {parameters_data}\")\n",
    "\n",
    "            pipeline = deepcopy(pipeline_base)\n",
    "\n",
    "            log_params(parameters_data)\n",
    "\n",
    "            pipeline.set_params(**parameters_data)\n",
    "\n",
    "            cv_results = cross_validate(\n",
    "                estimator=pipeline,\n",
    "                X=X_train,\n",
    "                y=y_train,\n",
    "                cv=cv_strategy,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                return_train_score=False  # TODO: Should I return those as well?\n",
    "            )\n",
    "\n",
    "            # 4. Log metrics for EACH FOLD to see stability\n",
    "            for scorer_name in scoring.keys():\n",
    "                for fold_index, fold_score in enumerate(cv_results[f'test_{scorer_name}']):\n",
    "                    # Log each fold's score as a step in the metric's history\n",
    "                    log_metric(key=f\"{scorer_name}_per_fold\", value=fold_score, step=fold_index)\n",
    "\n",
    "            # 5. Log SUMMARY metrics (mean, std) for easy comparison\n",
    "            summary_metrics = {}\n",
    "            for scorer_name in scoring.keys():\n",
    "                mean_score = np.mean(cv_results[f'test_{scorer_name}'])\n",
    "                std_score = np.std(cv_results[f'test_{scorer_name}'])\n",
    "\n",
    "                summary_metrics[f'mean_{scorer_name}'] = mean_score\n",
    "                summary_metrics[f'std_{scorer_name}'] = std_score\n",
    "\n",
    "            summary_metrics['mean_fit_time'] = np.mean(cv_results['fit_time'])\n",
    "            log_metrics(summary_metrics)\n",
    "            current_cost = summary_metrics['mean_business_cost']\n",
    "            if current_cost < best_global_score:\n",
    "                print(f\"  > Nouveau meilleur modèle trouvé ! Coût: {current_cost:.2f}\")\n",
    "                best_global_score = current_cost\n",
    "                best_model_name = run_name\n",
    "                best_model = deepcopy(pipeline_base)\n",
    "                best_params = parameters_data\n",
    "\n",
    "            if current_cost < local_best_global_score:\n",
    "                print(f\"  > Nouveau meilleur modèle trouvé ! Coût: {current_cost:.2f}\")\n",
    "                local_best_global_score = current_cost\n",
    "                local_best_model_name = run_name\n",
    "                local_best_model = deepcopy(pipeline_base)\n",
    "                local_best_params = parameters_data\n",
    "\n",
    "            print(f\"  > Run {run_name} terminé. Coût métier moyen: {-summary_metrics['mean_business_cost']:.2f}\")\n",
    "        model = deepcopy(local_best_model)\n",
    "        model.set_params(**local_best_params)\n",
    "        X_test = test.copy()\n",
    "        y_test = X_test.pop('TARGET')\n",
    "        model.fit(X_train, y_train)\n",
    "        sklearn.log_model(pipeline, name=local_best_model_name, signature=models.infer_signature(\n",
    "            X_test.head(), model.predict(X_test.head()), local_best_params))\n",
    "    print(f\"--- Run pour {model_name} terminé et loggé. ---\\n\")\n",
    "\n",
    "with start_run(run_name=best_model_name) as run:\n",
    "    model = deepcopy(best_model)\n",
    "    model.set_params(**best_params)\n",
    "    X_test = test.copy()\n",
    "    y_test = X_test.pop('TARGET')\n",
    "    model.fit(X_train, y_train)\n",
    "    sklearn.log_model(pipeline, name=best_model_name, signature=models.infer_signature(\n",
    "        X_test.head(), model.predict(X_test.head()), best_params))\n",
    "\n",
    "print(\"\\n--- FIN DE LA RECHERCHE ---\")\n",
    "print(f\"Le meilleur modèle global est : {best_model_name} avec un coût métier de {best_global_score:.2f}\")"
   ],
   "id": "803ab883f5964312",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "X_train = train.copy()\n",
    "y_train = X_train.pop('TARGET')\n",
    "best_model.fit(X_train, y_train)\n",
    "X_test = test.copy()\n",
    "y_test = X_test.pop('TARGET')\n",
    "RocCurveDisplay.from_estimator(best_model, X_test, y_test, ax=ax)\n",
    "plt.title(\"Courbe ROC du meilleur modèle\")\n",
    "\n",
    "# Sauvegarde la figure en tant qu'artefact MLflow\n",
    "log_figure(fig, \"roc_curve.png\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "6541e9ea580478dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, RocCurveDisplay, roc_auc_score, accuracy_score, f1_score\n",
    "from copy import deepcopy\n",
    "\n",
    "# --- 1. Préparation des données ---\n",
    "# Assurons-nous d'avoir des jeux de données propres pour l'entraînement final et le test\n",
    "X_train = train.drop('TARGET', axis=1)\n",
    "y_train = train['TARGET']\n",
    "X_test = test.drop('TARGET', axis=1)\n",
    "y_test = test['TARGET']\n",
    "\n",
    "# --- 2. Création et entraînement du modèle final ---\n",
    "print(\"--- Entraînement du modèle final sur l'ensemble des données d'entraînement ---\")\n",
    "final_model = deepcopy(best_model)\n",
    "final_model.set_params(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "print(\"Entraînement terminé.\")\n",
    "\n",
    "# --- 3. Démarrage d'un run MLflow dédié au modèle champion ---\n",
    "with mlflow.start_run(run_name=f\"{best_model_name}_CHAMPION\") as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(f\"Run MLflow démarré avec succès. Run ID: {run_id}\")\n",
    "    print(\"Logging des informations du modèle champion...\")\n",
    "\n",
    "    # --- 4. Log des hyperparamètres et des tags ---\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.set_tag(\"model_status\", \"champion\")\n",
    "    mlflow.set_tag(\"training_data_shape\", X_train.shape)\n",
    "\n",
    "    # --- 5. Évaluation sur le jeu de test et log des métriques ---\n",
    "    y_pred_proba_test = final_model.predict_proba(X_test)\n",
    "\n",
    "    # Récupération du seuil métier optimal calculé sur le jeu d'entraînement (pratique standard)\n",
    "    # ou recalculé sur le test pour voir la performance pure (ici on le recalcule pour l'info)\n",
    "    optimal_threshold_test = scoring['business_threshold']._score_func(y_test, y_pred_proba_test)\n",
    "    business_cost_test = scoring['business_cost']._score_func(y_test, y_pred_proba_test)\n",
    "\n",
    "    # Prédictions de classe avec le seuil optimisé\n",
    "    y_pred_class_test = (y_pred_proba_test[:, 1] >= optimal_threshold_test).astype(int)\n",
    "\n",
    "    # Calcul des métriques\n",
    "    test_metrics = {\n",
    "        \"test_business_cost\": business_cost_test,\n",
    "        \"test_optimal_threshold\": optimal_threshold_test,\n",
    "        \"test_roc_auc\": roc_auc_score(y_test, y_pred_proba_test[:, 1]),\n",
    "        \"test_accuracy_at_threshold\": accuracy_score(y_test, y_pred_class_test),\n",
    "        \"test_f1_at_threshold\": f1_score(y_test, y_pred_class_test)\n",
    "    }\n",
    "    mlflow.log_metrics(test_metrics)\n",
    "    print(\"Métriques sur le jeu de test logguées :\", test_metrics)\n",
    "\n",
    "    # --- 6. Création et log des artefacts visuels ---\n",
    "\n",
    "    # Matrice de confusion\n",
    "    fig_cm, ax_cm = plt.subplots()\n",
    "    cm = confusion_matrix(y_test, y_pred_class_test)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=ax_cm, cmap='Blues')\n",
    "    ax_cm.set_title(f'Matrice de Confusion (Seuil = {optimal_threshold_test:.2f})')\n",
    "    ax_cm.set_xlabel('Prédiction')\n",
    "    ax_cm.set_ylabel('Vraie valeur')\n",
    "    mlflow.log_figure(fig_cm, \"test_confusion_matrix.png\")\n",
    "    plt.close(fig_cm)\n",
    "\n",
    "    # Courbe ROC\n",
    "    fig_roc, ax_roc = plt.subplots()\n",
    "    RocCurveDisplay.from_estimator(final_model, X_test, y_test, ax=ax_roc)\n",
    "    ax_roc.set_title(\"Courbe ROC sur le jeu de test\")\n",
    "    mlflow.log_figure(fig_roc, \"test_roc_curve.png\")\n",
    "    plt.close(fig_roc)\n",
    "\n",
    "    print(\"Artefacts visuels (Matrice de Confusion, Courbe ROC) loggués.\")\n",
    "\n",
    "    # Analyse SHAP (peut prendre un peu de temps)\n",
    "    print(\"Calcul des valeurs SHAP pour l'interprétabilité...\")\n",
    "    # Il faut appliquer le preprocessing avant de le passer à l'explainer\n",
    "    # On récupère le pipeline de preprocessing et le modèle\n",
    "    preprocessor = final_model[:-1] # Toutes les étapes sauf la dernière ('model')\n",
    "    model_step = final_model.named_steps['model']\n",
    "\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # SHAP a besoin de noms de features valides\n",
    "    X_test_transformed.columns = [f'feature_{i}' for i in range(X_test_transformed.shape[1])]\n",
    "\n",
    "    explainer = shap.TreeExplainer(model_step)\n",
    "    shap_values = explainer(X_test_transformed)\n",
    "\n",
    "    # Graphique d'importance globale\n",
    "    fig_shap, ax_shap = plt.subplots()\n",
    "    shap.summary_plot(shap_values, X_test_transformed, show=False, max_display=20)\n",
    "    plt.title(\"Importance globale des features (SHAP)\")\n",
    "    # Ajuster la mise en page pour éviter que les labels ne soient coupés\n",
    "    plt.tight_layout()\n",
    "    mlflow.log_figure(plt.gcf(), \"test_shap_summary.png\")\n",
    "    plt.close(fig_shap)\n",
    "    print(\"Graphique SHAP loggué.\")\n",
    "\n",
    "    # --- 7. Log du modèle final ---\n",
    "    # La signature permet à MLflow de connaître les types d'entrée et de sortie\n",
    "    signature = mlflow.models.infer_signature(X_train.head(), final_model.predict_proba(X_train.head()))\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=final_model,\n",
    "        artifact_path=\"credit_scoring_model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=f\"{best_model_name}_champion_model\" # Enregistre directement le modèle dans le Model Registry\n",
    "    )\n",
    "    print(\"Modèle final loggué et enregistré dans le Model Registry.\")\n",
    "\n",
    "print(\"\\n--- OPÉRATION TERMINÉE ---\")\n",
    "print(f\"Le modèle champion a été entraîné, évalué et toutes ses informations sont disponibles dans le run ID: {run_id}\")"
   ],
   "id": "da4fcba41518f7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Partie 4 - Analyse des Résultats et Prochaines Étapes\n",
    "\n",
    "Toutes nos expérimentations sont maintenant enregistrées. Pour les visualiser, lance l'interface utilisateur de MLflow via \"http://127.65.12.247:50222\"\n",
    "\n",
    "\n",
    "Dans l'interface, tu pourras :\n",
    "- **Comparer les modèles** en les sélectionnant et en cliquant sur \"Compare\".\n",
    "- **Trier les runs** par `business_cost_mean` (le score le plus bas est le meilleur) ou `roc_auc_mean`.\n",
    "- **Inspecter chaque run** pour voir les paramètres exacts qui ont produit un certain résultat.\n",
    "\n",
    "### Prochaines étapes basées sur ces résultats :\n",
    "\n",
    "1.  **Choisir le meilleur modèle** : Sur la base du score métier, sélectionne le modèle le plus prometteur (probablement LightGBM).\n",
    "2.  **Optimisation des hyperparamètres** : Pour le modèle choisi, tu pourras lancer une nouvelle série d'expérimentations (par exemple avec `GridSearchCV` ou `Hyperopt`) pour trouver les meilleurs hyperparamètres, toujours en optimisant le score métier. Chaque essai de la recherche d'hyperparamètres peut être un `run` MLflow imbriqué !\n",
    "3.  **Analyse de l'importance des features** : Une fois le modèle finalisé, utilise des librairies comme **SHAP** pour analyser l'importance des features globale et locale, comme demandé dans le brief.\n",
    "4.  **Enregistrement du modèle final** : Le meilleur run pourra être promu dans le \"Model Registry\" de MLflow, lui donnant un statut (Staging, Production) pour le déploiement."
   ],
   "id": "c14f928412b25f37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
